{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0: R^2 = 0.2657497438376205\n",
      "Alpha = 0.001: R^2 = 0.2690308236549174\n",
      "Alpha = 0.005: R^2 = 0.2690308213219027\n",
      "Alpha = 0.01: R^2 = 0.26903081840093557\n",
      "Alpha = 0.05: R^2 = 0.2690307948459575\n",
      "Alpha = 0.1: R^2 = 0.26903076493752254\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from patsy import dmatrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "data = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "# Remover colunas desnecessárias\n",
    "data = data.drop(['Unnamed: 0', 'data_ref', 'id_cliente'], axis=1)\n",
    "\n",
    "# Converter variáveis categóricas em dummies\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "# Separar variáveis independentes (X) e dependente (y)\n",
    "X = data.drop('renda', axis=1)\n",
    "y = data['renda']\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste (75% treinamento, 25% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Lidar com valores ausentes apenas nos dados de treinamento\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Escalonar os recursos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Definir os valores de alpha\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Para armazenar os resultados\n",
    "ridge_results = {}\n",
    "\n",
    "# Iterar sobre os valores de alpha\n",
    "for alpha in alphas:\n",
    "    # Inicializar o modelo de regressão Ridge\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    \n",
    "    # Ajustar o modelo aos dados de treinamento\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Fazer previsões nos dados de teste\n",
    "    y_pred = ridge.predict(X_test_scaled)\n",
    "    \n",
    "    # Calcular o R^2 nos dados de teste\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    ridge_results[alpha] = r2\n",
    "\n",
    "# Imprimir os resultados\n",
    "for alpha, r2 in ridge_results.items():\n",
    "    print(f\"Alpha = {alpha}: R^2 = {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor modelo seria aquele com o maior valor de R^2 nos dados de teste, pois indica que o modelo tem a melhor capacidade de explicar a variabilidade da variável dependente (renda). Neste caso, o R^2 é praticamente o mesmo para todos os valores de alpha, o que sugere que a regularização Ridge não está tendo um efeito significativo na performance do modelo. No entanto, o modelo com alpha igual a 0.001 tem um R^2 ligeiramente maior, então poderíamos considerá-lo como o \"melhor\" modelo entre os testados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.858e+11, tolerance: 7.723e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.667e+11, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.061e+11, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.551e+11, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.414e+10, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0: R^2 (treinamento) = 0.2598159918234846, R^2 (teste) = 0.2690308673401247\n",
      "Alpha = 0.001: R^2 (treinamento) = 0.2598159911623643, R^2 (teste) = 0.2690308653726393\n",
      "Alpha = 0.005: R^2 (treinamento) = 0.25981598799705097, R^2 (teste) = 0.26903085701459406\n",
      "Alpha = 0.01: R^2 (treinamento) = 0.25981598286823326, R^2 (teste) = 0.2690308454691146\n",
      "Alpha = 0.05: R^2 (treinamento) = 0.2598158949365508, R^2 (teste) = 0.26903044034096146\n",
      "Alpha = 0.1: R^2 (treinamento) = 0.2598156678057444, R^2 (teste) = 0.2690299069787111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+10, tolerance: 7.723e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Definir os valores de alpha\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Para armazenar os resultados\n",
    "lasso_results = {}\n",
    "\n",
    "# Iterar sobre os valores de alpha\n",
    "for alpha in alphas:\n",
    "    # Inicializar o modelo de regressão Lasso\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    \n",
    "    # Ajustar o modelo aos dados de treinamento\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Calcular o R^2 nos dados de treinamento\n",
    "    r2_train = lasso.score(X_train_scaled, y_train)\n",
    "    \n",
    "    # Calcular o R^2 nos dados de teste\n",
    "    r2_test = lasso.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    lasso_results[alpha] = {'R^2 (treinamento)': r2_train, 'R^2 (teste)': r2_test}\n",
    "\n",
    "# Imprimir os resultados\n",
    "for alpha, result in lasso_results.items():\n",
    "    print(f\"Alpha = {alpha}: R^2 (treinamento) = {result['R^2 (treinamento)']}, R^2 (teste) = {result['R^2 (teste)']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor modelo seria aquele com o maior valor de R^2 nos dados de teste, pois indica que o modelo tem a melhor capacidade de explicar a variabilidade da variável dependente (renda). Neste caso, o R^2 é praticamente o mesmo para todos os valores de alpha, o que sugere que a regressão LASSO não está tendo um efeito significativo na performance do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adicionado sexo[M] com p-value 4.451346433934053e-205\n",
      "Adicionado tipo_renda[T.Servidor público] com p-value 1.4969129039111874e-11\n",
      "Adicionado tipo_renda[T.Pensionista] com p-value 1.090123161790028e-08\n",
      "Adicionado educacao[T.Superior incompleto] com p-value 6.867388441695818e-06\n",
      "Adicionado tipo_residencia[T.Com os pais] com p-value 0.00012096688830698076\n",
      "Adicionado educacao[T.Superior completo] com p-value 0.006015710774399351\n",
      "Adicionado sexo[F] com p-value 0.0011966903987365187\n",
      "R^2 na base de teste: 0.09554670063774084\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Carregar a base de dados\n",
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "# Remover as colunas 'Unnamed: 0', 'data_ref' e 'id_cliente'\n",
    "df = df.drop(columns=['Unnamed: 0', 'data_ref', 'id_cliente'])\n",
    "\n",
    "# Criar variáveis dummy\n",
    "formula = 'renda ~ sexo + posse_de_veiculo + posse_de_imovel + tipo_renda + educacao + estado_civil + tipo_residencia - 1'\n",
    "y, X = patsy.dmatrices(formula, df, return_type='dataframe')\n",
    "\n",
    "# Separar em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Definir função para seleção de características stepwise\n",
    "def stepwise_selection(X, y, initial_list=[], threshold_in=0.01, threshold_out=0.05, verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed = False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed = True\n",
    "            if verbose:\n",
    "                print(f'Adicionado {best_feature} com p-value {best_pval}')\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max()\n",
    "        if worst_pval > threshold_out:\n",
    "            changed = True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print(f'Removido {worst_feature} com p-value {worst_pval}')\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "# Executar o modelo stepwise\n",
    "selected_features = stepwise_selection(X_train, y_train['renda'])\n",
    "\n",
    "# Ajustar o modelo final aos dados de treinamento\n",
    "X_train_stepwise = X_train[selected_features]\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_stepwise, y_train)\n",
    "\n",
    "# Aplicar a seleção de características aos dados de teste\n",
    "X_test_stepwise = X_test[selected_features]\n",
    "\n",
    "# Calcular o R^2 na base de teste\n",
    "r2_test = model.score(X_test_stepwise, y_test)\n",
    "print(f\"R^2 na base de teste: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor modelo seria aquele com o maior valor de R^2 nos dados de teste, pois indica que o modelo tem a melhor capacidade de explicar a variabilidade da variável dependente (renda). Neste caso, o R^2 eh muito baixo para tirar uma conclucao."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achei o regularizacao ridge o melhor ja que deu o maior R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 na base de teste com interações polinomiais: -6.53164631030022e+16\n",
      "R^2 na base de teste com seleção de características pelo Lasso: 0.0970731342188188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Engenharia de características: Adicionar interações polinomiais de segundo grau\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Ajustar o modelo de regressão linear aos dados de treinamento\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "# Avaliar o R^2 na base de testes\n",
    "r2_test_poly = model_poly.score(X_test_poly, y_test)\n",
    "print(f\"R^2 na base de teste com interações polinomiais: {r2_test_poly}\")\n",
    "\n",
    "# Seleção de características: Utilizar o modelo Lasso para selecionar características\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(X_train, y_train)\n",
    "selected_features_lasso = X_train.columns[lasso.coef_ != 0]\n",
    "\n",
    "# Ajustar o modelo final aos dados de treinamento com as características selecionadas\n",
    "X_train_selected_lasso = X_train[selected_features_lasso]\n",
    "model_selected_lasso = LinearRegression()\n",
    "model_selected_lasso.fit(X_train_selected_lasso, y_train)\n",
    "\n",
    "# Aplicar a seleção de características aos dados de teste\n",
    "X_test_selected_lasso = X_test[selected_features_lasso]\n",
    "\n",
    "# Calcular o R^2 na base de teste\n",
    "r2_test_selected_lasso = model_selected_lasso.score(X_test_selected_lasso, y_test)\n",
    "print(f\"R^2 na base de teste com seleção de características pelo Lasso: {r2_test_selected_lasso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 na base de teste com árvore de regressão: 0.09669755295702775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Ajustar uma árvore de regressão aos dados de treinamento\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X_train_stepwise, y_train)\n",
    "\n",
    "# Fazer previsões na base de teste\n",
    "y_pred_tree = tree_reg.predict(X_test_stepwise)\n",
    "\n",
    "# Calcular o R^2 na base de teste\n",
    "r2_test_tree = r2_score(y_test, y_pred_tree)\n",
    "print(f\"R^2 na base de teste com árvore de regressão: {r2_test_tree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
